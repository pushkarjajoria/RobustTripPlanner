{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview:\n",
    "In this notebook, we create the graph, which forms the backbone of our algorithm. We use networkx library for graph manipulations. We use the timetable data to create the graph. Each node in our graph corresponds to a stop and each edge between two nodes corresponds to a particular trip. There can exists multiple directed edges between two nodes, corresponding to different trip_ids. We also add walking edges between stops which are closer than 500m. \\\n",
    "Each directed edge (from station a to station b) in our graph has the following edge attributes:\n",
    "1. trip_id : trip_id from the timetable data or 'walk' for walking trips\n",
    "2. dep_time: Departure time from station a\n",
    "3. arr_time: Arrival time at station b\n",
    "4. walking_time: Only for walking edges, time taken to walk from station a to station b, at 50m/1min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from hdfs3 import HDFileSystem\n",
    "hdfs = HDFileSystem(user='ebouille')\n",
    "import os\n",
    "username = os.environ['JUPYTERHUB_USER']\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import heapq\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parquet_from_hdfs(filename):\n",
    "    files = hdfs.glob(f'/user/{username}/{filename}.parquet/*.parquet')\n",
    "    df = pd.DataFrame()\n",
    "    for file in files:\n",
    "        with hdfs.open(file) as f:\n",
    "            df = df.append(pd.read_parquet(f))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read relevant data\n",
    "stops = read_parquet_from_hdfs(\"stops\")\n",
    "stop_times = read_parquet_from_hdfs(\"stop_times\")\n",
    "calendar = read_parquet_from_hdfs(\"calendar\") \n",
    "routes = read_parquet_from_hdfs(\"routes\")\n",
    "trips = read_parquet_from_hdfs(\"trips\")\n",
    "\n",
    "def route_desc_to_product(x):\n",
    "    if x == 'Bus':\n",
    "        return u'bus'\n",
    "    elif x == 'Tram':\n",
    "        return u'tram'\n",
    "    elif x == 'Taxi':\n",
    "        return u''\n",
    "    else:\n",
    "        return 'zug'\n",
    "    \n",
    "routes['product_id'] = routes['route_desc'].map(route_desc_to_product)\n",
    "route_to_product = {row['route_id']: row['product_id'] for _, row in routes.iterrows()}\n",
    "trip_id_to_route = {row['trip_id']: row['route_id'] for _, row in trips.iterrows()}\n",
    "trip_to_product = {trip: route_to_product[trip_id_to_route[trip]]\n",
    "                  for trip in trips['trip_id'].unique()}\n",
    "product_id_map = {\n",
    "    u'': 0,\n",
    "    u'bus': 1,\n",
    "    u'tram': 2,\n",
    "    u'zug': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph-Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Multiple Edge Directed Graph -> G(V, E)\n",
    "G = nx.MultiDiGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each trip_id data frame, add edges from the source to destination with the scheduled arrival and departure time along with the trip id.\n",
    "Nodes/Vertices are also created in this as `networkx` will add a node if no such node is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add all edges corresponding to one trip_id to the graph \n",
    "def add_to_graph(df):\n",
    "    df_sorted = df.sort_values(['stop_sequence'])\n",
    "    stop_ids = df_sorted['stop_id']\n",
    "    weekly_cal = str(df_sorted.iloc[0]['monday']) + str(df_sorted.iloc[0]['tuesday']) + str(df_sorted.iloc[0]['wednesday']) + str(df_sorted.iloc[0]['thursday']) + str(df_sorted.iloc[0]['friday']) + str(df_sorted.iloc[0]['saturday']) + str(df_sorted.iloc[0]['sunday']) \n",
    "    attr = [{'dep':str(i[0])+':'+str(i[1]), \\\n",
    "             'arr':str(i[2])+':'+str(i[3]), \\\n",
    "             'trip_id':df_sorted.iloc[0]['trip_id'], \\\n",
    "             'weekly': weekly_cal} \\\n",
    "            for i in zip(df_sorted['departure_hour'][:-1],\\\n",
    "                         df_sorted['departure_minute'][:-1],\\\n",
    "                         df_sorted['arrival_hour'][1:],\\\n",
    "                         df_sorted['arrival_minute'][1:]\\\n",
    "                        )]\n",
    "    G.add_edges_from([*zip(stop_ids[0:-1],stop_ids[1:],attr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Time intensive task, usually requires 4-5 minutes\n",
    "stop_times\\\n",
    "    .merge(trips, on='trip_id', how='left')\\\n",
    "    .drop(columns=['drop_off_type', 'pickup_type', 'direction_id', 'route_id'])\\\n",
    "    .merge(calendar, on='service_id', how='left')\\\n",
    "    .drop(columns=['start_date', 'end_date'])\\\n",
    "    .groupby('trip_id')\\\n",
    "    .apply(add_to_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of Nodes (Stations) in the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(G.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(G.edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Walking Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_between_coordinates_km(lat1, lon1, lat2, lon2):\n",
    "    # Returns distance in km between two co-ordinates\n",
    "    from math import sin, cos, sqrt, atan2, radians\n",
    "\n",
    "    # approximate radius of earth in km\n",
    "    R = 6373.0\n",
    "\n",
    "    lat1 = radians(float(lat1))\n",
    "    lon1 = radians(float(lon1))\n",
    "    lat2 = radians(float(lat2))\n",
    "    lon2 = radians(float(lon2))\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(stops)-1):\n",
    "    stop_i = stops.iloc[i]\n",
    "    stops_rest = stops.iloc[i+1:]\n",
    "    stops_rest['dist_i'] = stops_rest.apply(lambda x: distance_between_coordinates_km(stop_i['stop_lat'], stop_i['stop_lon'], x['stop_lat'], x['stop_lon']) , axis=1)\n",
    "    stops_rest = stops_rest[stops_rest['dist_i']<=0.5]\n",
    "    attr = [{'walking_time':i_ , 'trip_id':'walk'} for i_ in (stops_rest['dist_i']*1000.0)/50.0]\n",
    "    G.add_edges_from([*zip([stop_i['stop_id']]*len(stops_rest),stops_rest['stop_id'],attr)])\n",
    "    G.add_edges_from([*zip(stops_rest['stop_id'], [stop_i['stop_id']]*len(stops_rest),attr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(G.edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the graph object into a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"/work/final-assignment-group-y/data/\"\n",
    "filename = \"graph.pickle\"\n",
    "filename_reverse = \"graph_reverse.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dir + filename, 'wb') as config_dictionary_file:\n",
    "    pickle.dump(G, config_dictionary_file)\n",
    "    \n",
    "with open(dir + filename_reverse, 'wb') as config_dictionary_file:\n",
    "    pickle.dump(G.reverse(copy=True), config_dictionary_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
